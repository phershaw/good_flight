{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERTopic\n",
    "\n",
    "BERTopic is an algorithm that generate topics from a collection of documents. It leverages BERT (Bidirectional Encoder Representations from Transformers), a powerful language representation model developed by Google, along with other machine learning techniques, to identify coherent and meaningful topics within large volumes of text. Unlike traditional topic modeling algorithms (like LDA) that rely on word frequency counts and distributions, BERTopic uses contextual embeddings. This means it understands the context in which words are used, allowing it to identify topics with greater accuracy and relevance.\n",
    "\n",
    "In this notebook, the model is trained on customer reviews from flights. I used the model out of the box, and would like to continue experimentation with hyperparameters.\n",
    "\n",
    "Training the model was time consuming, so we pickled the model to make it easy to use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from bertopic import BERTopic  \n",
    "from bertopic import BERTopic   \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('/Users/paulhershaw/brainstation_course/test_git/test/data/airline_reviews_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform basic text cleaning\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lower case\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Remove non-alphanumeric characters\n",
    "    text = re.sub(r'\\W+', ' ', text)\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the 'customer_review' column\n",
    "df['customer_review'] = df['customer_review'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of the cleaned reviews\n",
    "reviews_list = df['customer_review'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the BERTopic model\n",
    "topic_model = BERTopic(embedding_model=\"all-MiniLM-L6-v2\", \n",
    "                        calculate_probabilities=True, \n",
    "                        verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the reviews\n",
    "topics, probs = topic_model.fit_transform(reviews_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model for later use. \n",
    "with open('topic_model.pkl', 'wb') as file:\n",
    "    pickle.dump(topic_model, file)\n",
    "\n",
    "# Save the topics and probabilities\n",
    "with open('topics_probs.pkl', 'wb') as file:\n",
    "    pickle.dump((topics, probs), file)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
